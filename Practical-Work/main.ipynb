{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Config, get_scheduler\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from dataloader import CustomEncodingVocabulary, GPT2Dataset\n",
    "CustomEncodingVocabulary.initialize()\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from helper import get_next_run_folder\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-17T13:36:47.381616600Z",
     "start_time": "2025-02-17T13:36:47.373355200Z"
    }
   },
   "id": "cd6e01fa7f4e0a41",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 421\n",
      "Using device: xpu\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "num_epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "vocabulary = CustomEncodingVocabulary.tokens\n",
    "padding_token = CustomEncodingVocabulary.padding_token\n",
    "\n",
    "print(f'Vocabulary size: {len(vocabulary)}')\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=len(vocabulary),    # Size of your vocabulary (adjust to match your tokenizer)\n",
    "    n_positions=1024,   # Maximum sequence length\n",
    "    n_ctx=256,          # Context window size\n",
    "    n_embd=256,         # Embedding size\n",
    "    n_layer=2,          # Number of transformer layers\n",
    "    n_head=2,           # Number of attention heads\n",
    "    pad_token_id=padding_token,  # Set padding token ID (e.g., same as eos_token)\n",
    ")\n",
    "\n",
    "# Use appropriate gpu or cpu\n",
    "device = ('xpu' if torch.xpu.is_available() else\n",
    "          'cuda' if torch.cuda.is_available() else\n",
    "          'cpu')\n",
    "\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-17T13:36:47.382617600Z",
     "start_time": "2025-02-17T13:36:47.378696200Z"
    }
   },
   "id": "87af4c202b7c3c",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Instantiate GPT-2 model\n",
    "model = GPT2LMHeadModel(config)\n",
    "\n",
    "torch.save(model, 'gpt_model_empty.ph')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-17T13:36:47.435627100Z",
     "start_time": "2025-02-17T13:36:47.382617600Z"
    }
   },
   "id": "414d561771df2289",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get dataset and dataloader\n",
    "dataset = GPT2Dataset('ldp_5_dataset')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,  # Number of samples per batch\n",
    "        shuffle=False,  # This would fuck up our preloading\n",
    "        num_workers=0,  # This would fuck up our preloading as well... \n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-17T13:36:54.337593300Z",
     "start_time": "2025-02-17T13:36:47.436627600Z"
    }
   },
   "id": "84999897840c4d5a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: runs\\GPT2_Model_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12497 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBackendCompilerFailed\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 54\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# Forward pass using half precision to get away with even less memory\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautocast(device_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mxpu\u001B[39m\u001B[38;5;124m'\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat16):\n\u001B[1;32m---> 54\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;66;03m# GPT-2 directly computes the loss if labels are provided\u001B[39;00m\n\u001B[0;32m     58\u001B[0m     loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss  \n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:574\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    569\u001B[0m saved_dynamic_layer_stack_depth \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    570\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_functorch\u001B[38;5;241m.\u001B[39mget_dynamic_layer_stack_depth()\n\u001B[0;32m    571\u001B[0m )\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001B[39;00m\n\u001B[0;32m    577\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_functorch\u001B[38;5;241m.\u001B[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001B[0;32m    578\u001B[0m         saved_dynamic_layer_stack_depth\n\u001B[0;32m    579\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1061\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1053\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1055\u001B[0m \u001B[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[0;32m   1058\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1059\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1061\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1062\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1063\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1064\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1065\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1066\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1067\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1070\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1071\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1072\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1073\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1074\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1075\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1076\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1078\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1380\u001B[0m, in \u001B[0;36mCatchErrorsWrapper.__call__\u001B[1;34m(self, frame, cache_entry, frame_state)\u001B[0m\n\u001B[0;32m   1374\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m hijacked_callback(\n\u001B[0;32m   1375\u001B[0m                 frame, cache_entry, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks, frame_state\n\u001B[0;32m   1376\u001B[0m             )\n\u001B[0;32m   1378\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compile_lock, _disable_current_modes():\n\u001B[0;32m   1379\u001B[0m     \u001B[38;5;66;03m# skip=1: skip this frame\u001B[39;00m\n\u001B[1;32m-> 1380\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_torchdynamo_orig_callable\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[0;32m   1382\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1164\u001B[0m, in \u001B[0;36mConvertFrame.__call__\u001B[1;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001B[0m\n\u001B[0;32m   1162\u001B[0m counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframes\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1163\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1164\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inner_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1165\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[0;32m   1166\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1167\u001B[0m     counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframes\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1168\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:547\u001B[0m, in \u001B[0;36mConvertFrameAssert.__call__\u001B[1;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001B[0m\n\u001B[0;32m    544\u001B[0m     dynamo_tls\u001B[38;5;241m.\u001B[39mtraced_frame_infos\u001B[38;5;241m.\u001B[39mappend(info)\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compile_context(CompileContext(compile_id)):\n\u001B[1;32m--> 547\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    549\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_globals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_locals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_builtins\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_torchdynamo_orig_callable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_one_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    555\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_export\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_export_constraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    560\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    561\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    562\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcompile_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompile_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    563\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:986\u001B[0m, in \u001B[0;36m_compile\u001B[1;34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001B[0m\n\u001B[0;32m    984\u001B[0m guarded_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 986\u001B[0m     guarded_code \u001B[38;5;241m=\u001B[39m \u001B[43mcompile_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001B[39;00m\n\u001B[0;32m    989\u001B[0m     \u001B[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001B[39;00m\n\u001B[0;32m    990\u001B[0m     \u001B[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    995\u001B[0m     \u001B[38;5;66;03m# to upload for graph break though, because this can prevent\u001B[39;00m\n\u001B[0;32m    996\u001B[0m     \u001B[38;5;66;03m# extra graph break compilations.)\u001B[39;00m\n\u001B[0;32m    997\u001B[0m     put_code_state()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:715\u001B[0m, in \u001B[0;36m_compile.<locals>.compile_inner\u001B[1;34m(code, one_graph, hooks, transform)\u001B[0m\n\u001B[0;32m    713\u001B[0m     stack\u001B[38;5;241m.\u001B[39menter_context(torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39minstall_callbacks())\n\u001B[0;32m    714\u001B[0m     stack\u001B[38;5;241m.\u001B[39menter_context(CompileTimeInstructionCounter\u001B[38;5;241m.\u001B[39mrecord())\n\u001B[1;32m--> 715\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_utils_internal.py:95\u001B[0m, in \u001B[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     92\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m skip \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m StrobelightCompileTimeProfiler\u001B[38;5;241m.\u001B[39menabled:\n\u001B[1;32m---> 95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m StrobelightCompileTimeProfiler\u001B[38;5;241m.\u001B[39mprofile_compile_time(\n\u001B[0;32m     98\u001B[0m     function, phase_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m     99\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:750\u001B[0m, in \u001B[0;36m_compile.<locals>._compile_inner\u001B[1;34m(code, one_graph, hooks, transform)\u001B[0m\n\u001B[0;32m    748\u001B[0m CompileContext\u001B[38;5;241m.\u001B[39mget()\u001B[38;5;241m.\u001B[39mattempt \u001B[38;5;241m=\u001B[39m attempt\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 750\u001B[0m     out_code \u001B[38;5;241m=\u001B[39m \u001B[43mtransform_code_object\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    751\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    752\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mRestartAnalysis \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py:1361\u001B[0m, in \u001B[0;36mtransform_code_object\u001B[1;34m(code, transformations, safe)\u001B[0m\n\u001B[0;32m   1358\u001B[0m instructions \u001B[38;5;241m=\u001B[39m cleaned_instructions(code, safe)\n\u001B[0;32m   1359\u001B[0m propagate_line_nums(instructions)\n\u001B[1;32m-> 1361\u001B[0m \u001B[43mtransformations\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstructions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:231\u001B[0m, in \u001B[0;36mpreserve_global_state.<locals>._fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    229\u001B[0m exit_stack\u001B[38;5;241m.\u001B[39menter_context(torch_function_mode_stack_state_mgr)\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 231\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m     cleanup\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:662\u001B[0m, in \u001B[0;36m_compile.<locals>.transform\u001B[1;34m(instructions, code_options)\u001B[0m\n\u001B[0;32m    660\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    661\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tracing(tracer\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mtracing_context), tracer\u001B[38;5;241m.\u001B[39mset_current_tx():\n\u001B[1;32m--> 662\u001B[0m         \u001B[43mtracer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    663\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mUnspecializeRestartAnalysis:\n\u001B[0;32m    664\u001B[0m     speculation_log\u001B[38;5;241m.\u001B[39mclear()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2868\u001B[0m, in \u001B[0;36mInstructionTranslator.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2867\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m-> 2868\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:1052\u001B[0m, in \u001B[0;36mInstructionTranslatorBase.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mpush_tx(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m-> 1052\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1053\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:962\u001B[0m, in \u001B[0;36mInstructionTranslatorBase.step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    959\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_block_stack(inst)\n\u001B[0;32m    961\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 962\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_table\u001B[49m\u001B[43m[\u001B[49m\u001B[43minst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopcode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    963\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mshould_exit\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:657\u001B[0m, in \u001B[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001B[1;34m(self, inst)\u001B[0m\n\u001B[0;32m    655\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m speculation\u001B[38;5;241m.\u001B[39mfailed:\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m speculation\u001B[38;5;241m.\u001B[39mreason \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhandle_graph_break\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspeculation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreason\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    659\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_fn(\u001B[38;5;28mself\u001B[39m, inst)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:698\u001B[0m, in \u001B[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.handle_graph_break\u001B[1;34m(self, inst, reason)\u001B[0m\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mhandle_graph_break\u001B[39m(\n\u001B[0;32m    694\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstructionTranslatorBase\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    695\u001B[0m     inst: Instruction,\n\u001B[0;32m    696\u001B[0m     reason: GraphCompileReason,\n\u001B[0;32m    697\u001B[0m ):\n\u001B[1;32m--> 698\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_subgraph\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreason\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreason\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    699\u001B[0m     cg \u001B[38;5;241m=\u001B[39m PyCodegen(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    700\u001B[0m     cleanup: List[Instruction] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1136\u001B[0m, in \u001B[0;36mOutputGraph.compile_subgraph\u001B[1;34m(self, tx, partial_convert, reason)\u001B[0m\n\u001B[0;32m   1133\u001B[0m output \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m count_calls(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(pass2\u001B[38;5;241m.\u001B[39mgraph_outputs) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1135\u001B[0m     output\u001B[38;5;241m.\u001B[39mextend(\n\u001B[1;32m-> 1136\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_and_call_fx_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1137\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpass2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_output_vars\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_replacements\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1139\u001B[0m     )\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(pass2\u001B[38;5;241m.\u001B[39mgraph_outputs) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1142\u001B[0m         output\u001B[38;5;241m.\u001B[39mappend(pass2\u001B[38;5;241m.\u001B[39mcreate_store(graph_output_var))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1382\u001B[0m, in \u001B[0;36mOutputGraph.compile_and_call_fx_graph\u001B[1;34m(self, tx, rv, root, replaced_outputs)\u001B[0m\n\u001B[0;32m   1379\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracing_context\u001B[38;5;241m.\u001B[39mfake_mode \u001B[38;5;241m=\u001B[39m backend_fake_mode\n\u001B[0;32m   1381\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestore_global_state():\n\u001B[1;32m-> 1382\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_user_compiler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_lazy_graph_module\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _LazyGraphModule\n\u001B[0;32m   1386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(compiled_fn, _LazyGraphModule) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   1387\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(compiled_fn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__self__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m), _LazyGraphModule)\n\u001B[0;32m   1388\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m compiled_fn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_lazy_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1392\u001B[0m     \u001B[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001B[39;00m\n\u001B[0;32m   1393\u001B[0m     \u001B[38;5;66;03m# optimize a _LazyGraphModule.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1432\u001B[0m, in \u001B[0;36mOutputGraph.call_user_compiler\u001B[1;34m(self, gm)\u001B[0m\n\u001B[0;32m   1425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcall_user_compiler\u001B[39m(\u001B[38;5;28mself\u001B[39m, gm: fx\u001B[38;5;241m.\u001B[39mGraphModule) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m CompiledFn:\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\n\u001B[0;32m   1427\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutputGraph.call_user_compiler\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1428\u001B[0m         phase_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackend_compile\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1429\u001B[0m         log_pt2_compile_event\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   1430\u001B[0m         dynamo_compile_column_us\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot_autograd_cumulative_compile_time_us\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1431\u001B[0m     ):\n\u001B[1;32m-> 1432\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_user_compiler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1483\u001B[0m, in \u001B[0;36mOutputGraph._call_user_compiler\u001B[1;34m(self, gm)\u001B[0m\n\u001B[0;32m   1481\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m   1482\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1483\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BackendCompilerFailed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiler_fn, e)\u001B[38;5;241m.\u001B[39mwith_traceback(\n\u001B[0;32m   1484\u001B[0m         e\u001B[38;5;241m.\u001B[39m__traceback__\n\u001B[0;32m   1485\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1487\u001B[0m signpost_event(\n\u001B[0;32m   1488\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1489\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutputGraph.call_user_compiler\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1495\u001B[0m     },\n\u001B[0;32m   1496\u001B[0m )\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1462\u001B[0m, in \u001B[0;36mOutputGraph._call_user_compiler\u001B[1;34m(self, gm)\u001B[0m\n\u001B[0;32m   1460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mverify_correctness:\n\u001B[0;32m   1461\u001B[0m     compiler_fn \u001B[38;5;241m=\u001B[39m WrapperBackend(compiler_fn)\n\u001B[1;32m-> 1462\u001B[0m compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexample_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1463\u001B[0m _step_logger()(logging\u001B[38;5;241m.\u001B[39mINFO, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone compiler function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(compiled_fn), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompiler_fn did not return callable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py:130\u001B[0m, in \u001B[0;36mWrapBackendDebug.__call__\u001B[1;34m(self, gm, example_inputs, **kwargs)\u001B[0m\n\u001B[0;32m    128\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 130\u001B[0m     compiled_gm \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_gm\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\__init__.py:2340\u001B[0m, in \u001B[0;36m_TorchCompileInductorWrapper.__call__\u001B[1;34m(self, model_, inputs_)\u001B[0m\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, model_, inputs_):\n\u001B[0;32m   2338\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompile_fx\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m compile_fx\n\u001B[1;32m-> 2340\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompile_fx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig_patches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1863\u001B[0m, in \u001B[0;36mcompile_fx\u001B[1;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001B[0m\n\u001B[0;32m   1856\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001B[0;32m   1858\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m V\u001B[38;5;241m.\u001B[39mset_fake_mode(fake_mode), torch\u001B[38;5;241m.\u001B[39m_guards\u001B[38;5;241m.\u001B[39mtracing(\n\u001B[0;32m   1859\u001B[0m     tracing_context\n\u001B[0;32m   1860\u001B[0m ), compiled_autograd\u001B[38;5;241m.\u001B[39m_disable(), functorch_config\u001B[38;5;241m.\u001B[39mpatch(\n\u001B[0;32m   1861\u001B[0m     unlift_effect_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1862\u001B[0m ):\n\u001B[1;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43maot_autograd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1864\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfw_compiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfw_compiler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbw_compiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbw_compiler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1866\u001B[0m \u001B[43m        \u001B[49m\u001B[43minference_compiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minference_compiler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1867\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecompositions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecompositions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1868\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartition_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartition_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1869\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_inference_input_mutations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1870\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcudagraphs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcudagraphs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1871\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py:83\u001B[0m, in \u001B[0;36mAotAutograd.__call__\u001B[1;34m(self, gm, example_inputs, **kwargs)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;66;03m# NB: NOT cloned!\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m enable_aot_logging(), patch_config:\n\u001B[1;32m---> 83\u001B[0m         cg \u001B[38;5;241m=\u001B[39m \u001B[43maot_module_simplified\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m         counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot_autograd\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m disable(cg)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1155\u001B[0m, in \u001B[0;36maot_module_simplified\u001B[1;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m AOTAutogradCache\u001B[38;5;241m.\u001B[39mload(\n\u001B[0;32m   1146\u001B[0m         dispatch_and_compile,\n\u001B[0;32m   1147\u001B[0m         mod,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1152\u001B[0m         remote,\n\u001B[0;32m   1153\u001B[0m     )\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1155\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mdispatch_and_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mGmWrapper):\n\u001B[0;32m   1158\u001B[0m     \u001B[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001B[39;00m\n\u001B[0;32m   1159\u001B[0m     \u001B[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001B[39;00m\n\u001B[0;32m   1160\u001B[0m     \u001B[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001B[39;00m\n\u001B[0;32m   1161\u001B[0m     \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001B[39;00m\n\u001B[0;32m   1162\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mboxed_forward\u001B[39m(runtime_args: List[Any]):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1131\u001B[0m, in \u001B[0;36maot_module_simplified.<locals>.dispatch_and_compile\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1129\u001B[0m functional_call \u001B[38;5;241m=\u001B[39m create_functional_call(mod, params_spec, params_len)\n\u001B[0;32m   1130\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compiled_autograd\u001B[38;5;241m.\u001B[39m_disable():\n\u001B[1;32m-> 1131\u001B[0m     compiled_fn, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_aot_dispatcher_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunctional_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfake_flat_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1134\u001B[0m \u001B[43m        \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfake_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshape_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1137\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:580\u001B[0m, in \u001B[0;36mcreate_aot_dispatcher_function\u001B[1;34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001B[0m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate_aot_dispatcher_function\u001B[39m(\n\u001B[0;32m    573\u001B[0m     flat_fn,\n\u001B[0;32m    574\u001B[0m     fake_flat_args: FakifiedFlatArgs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    577\u001B[0m     shape_env: Optional[ShapeEnv],\n\u001B[0;32m    578\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Callable, ViewAndMutationMeta]:\n\u001B[0;32m    579\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_aot_dispatcher_function\u001B[39m\u001B[38;5;124m\"\u001B[39m, log_pt2_compile_event\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 580\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_create_aot_dispatcher_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[43m            \u001B[49m\u001B[43mflat_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape_env\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:830\u001B[0m, in \u001B[0;36m_create_aot_dispatcher_function\u001B[1;34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001B[0m\n\u001B[0;32m    826\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m aot_dispatch_base\n\u001B[0;32m    828\u001B[0m compiler_fn \u001B[38;5;241m=\u001B[39m choose_dispatcher(needs_autograd, aot_config)\n\u001B[1;32m--> 830\u001B[0m compiled_fn, fw_metadata \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_dup_fake_script_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfake_flat_args\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43maot_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfw_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfw_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn, fw_metadata\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py:678\u001B[0m, in \u001B[0;36maot_dispatch_autograd\u001B[1;34m(flat_fn, flat_args, aot_config, fw_metadata)\u001B[0m\n\u001B[0;32m    675\u001B[0m     tracing_context\u001B[38;5;241m.\u001B[39mfw_metadata \u001B[38;5;241m=\u001B[39m inner_meta\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m TracingContext\u001B[38;5;241m.\u001B[39mreport_output_strides() \u001B[38;5;28;01mas\u001B[39;00m fwd_output_strides:\n\u001B[1;32m--> 678\u001B[0m     compiled_fw_func \u001B[38;5;241m=\u001B[39m \u001B[43maot_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfw_compiler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfw_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjusted_flat_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    680\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(compiled_fw_func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_boxed_call\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    681\u001B[0m     compiled_fw_func \u001B[38;5;241m=\u001B[39m make_boxed_func(compiled_fw_func)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:489\u001B[0m, in \u001B[0;36mSerializableAOTDispatchCompiler.__call__\u001B[1;34m(self, gm, example_inputs)\u001B[0m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m    485\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    486\u001B[0m     gm: torch\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mGraphModule,\n\u001B[0;32m    487\u001B[0m     example_inputs: Sequence[InputType],\n\u001B[0;32m    488\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutputCode:\n\u001B[1;32m--> 489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1741\u001B[0m, in \u001B[0;36mcompile_fx.<locals>.fw_compiler_base\u001B[1;34m(gm, example_inputs, is_inference)\u001B[0m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1739\u001B[0m     model_outputs_node\u001B[38;5;241m.\u001B[39mmeta[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_visible_output_idxs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m-> 1741\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstatic_input_idxs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_static_input_idxs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfixed\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcudagraphs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcudagraphs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgraph_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1747\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_inference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_inference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1748\u001B[0m \u001B[43m    \u001B[49m\u001B[43mboxed_forward_device_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforward_device\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1749\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:569\u001B[0m, in \u001B[0;36mcompile_fx_inner\u001B[1;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[0;32m    562\u001B[0m stack\u001B[38;5;241m.\u001B[39menter_context(DebugContext())\n\u001B[0;32m    564\u001B[0m get_chromium_event_logger()\u001B[38;5;241m.\u001B[39madd_event_data(\n\u001B[0;32m    565\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minductor_compile\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    566\u001B[0m     is_backward\u001B[38;5;241m=\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    567\u001B[0m )\n\u001B[1;32m--> 569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrap_compiler_debug\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_compile_fx_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompiler_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minductor\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    572\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    573\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py:102\u001B[0m, in \u001B[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001B[1;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrepro_after \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001B[39;00m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;66;03m# with fake inputs\u001B[39;00m\n\u001B[1;32m--> 102\u001B[0m     inner_compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001B[39;00m\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;66;03m# need a different serialization strategy\u001B[39;00m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrepro_after \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:685\u001B[0m, in \u001B[0;36m_compile_fx_inner\u001B[1;34m(gm, example_inputs, **graph_kwargs)\u001B[0m\n\u001B[0;32m    683\u001B[0m TritonBundler\u001B[38;5;241m.\u001B[39mbegin_compile()\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 685\u001B[0m     mb_compiled_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfx_codegen_and_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    686\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_to_check\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgraph_kwargs\u001B[49m\n\u001B[0;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    688\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m mb_compiled_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    689\u001B[0m     mb_compiled_graph\u001B[38;5;241m.\u001B[39m_time_taken_ns \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime_ns() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1129\u001B[0m, in \u001B[0;36mfx_codegen_and_compile\u001B[1;34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001B[0m\n\u001B[0;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfx_codegen_and_compile\u001B[39m(\n\u001B[0;32m   1120\u001B[0m     gm: GraphModule,\n\u001B[0;32m   1121\u001B[0m     example_inputs: Sequence[InputType],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1125\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgraph_kwargs: Unpack[_CompileFxKwargs],\n\u001B[0;32m   1126\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutputCode:\n\u001B[0;32m   1127\u001B[0m     scheme: FxCompile \u001B[38;5;241m=\u001B[39m _InProcessFxCompile()\n\u001B[1;32m-> 1129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscheme\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcodegen_and_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_to_check\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1044\u001B[0m, in \u001B[0;36m_InProcessFxCompile.codegen_and_compile\u001B[1;34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001B[0m\n\u001B[0;32m   1036\u001B[0m             compiled_fn \u001B[38;5;241m=\u001B[39m AotCodeCompiler\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[0;32m   1037\u001B[0m                 graph,\n\u001B[0;32m   1038\u001B[0m                 code,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1041\u001B[0m                 additional_files\u001B[38;5;241m=\u001B[39madditional_files,\n\u001B[0;32m   1042\u001B[0m             )\n\u001B[0;32m   1043\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1044\u001B[0m         compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_to_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcall\n\u001B[0;32m   1046\u001B[0m num_bytes, nodes_num_elem, node_runtimes \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39mcount_bytes()\n\u001B[0;32m   1047\u001B[0m metrics\u001B[38;5;241m.\u001B[39mnum_bytes_accessed \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m num_bytes\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\graph.py:2027\u001B[0m, in \u001B[0;36mGraphLowering.compile_to_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2020\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompile_to_module\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModuleType:\n\u001B[0;32m   2021\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\n\u001B[0;32m   2022\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGraphLowering.compile_to_module\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2023\u001B[0m         phase_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_gen\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2024\u001B[0m         log_pt2_compile_event\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   2025\u001B[0m         dynamo_compile_column_us\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minductor_code_gen_cumulative_compile_time_us\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2026\u001B[0m     ):\n\u001B[1;32m-> 2027\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compile_to_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\graph.py:2033\u001B[0m, in \u001B[0;36mGraphLowering._compile_to_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2029\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_compile_to_module\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModuleType:\n\u001B[0;32m   2030\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcodecache\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PyCodeCache\n\u001B[0;32m   2032\u001B[0m     code, linemap \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m-> 2033\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcodegen_with_cpp_wrapper() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcpp_wrapper \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcodegen\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2034\u001B[0m     )\n\u001B[0;32m   2035\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mtriton\u001B[38;5;241m.\u001B[39mautotune_at_compile_time:\n\u001B[0;32m   2036\u001B[0m         tuning_code \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   2037\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2038\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompile-time auto-tuning block: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2041\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2042\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\graph.py:1964\u001B[0m, in \u001B[0;36mGraphLowering.codegen\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscheduler\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Scheduler\n\u001B[0;32m   1962\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_wrapper_code()\n\u001B[1;32m-> 1964\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler \u001B[38;5;241m=\u001B[39m \u001B[43mScheduler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moperations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1965\u001B[0m V\u001B[38;5;241m.\u001B[39mdebug\u001B[38;5;241m.\u001B[39mdraw_orig_fx_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_gm, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mnodes)\n\u001B[0;32m   1967\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrapper_code\u001B[38;5;241m.\u001B[39mpush_codegened_graph(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1798\u001B[0m, in \u001B[0;36mScheduler.__init__\u001B[1;34m(self, nodes)\u001B[0m\n\u001B[0;32m   1796\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, nodes: List[ir\u001B[38;5;241m.\u001B[39mOperation]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1797\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScheduler.__init__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1798\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1816\u001B[0m, in \u001B[0;36mScheduler._init\u001B[1;34m(self, nodes)\u001B[0m\n\u001B[0;32m   1807\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompleted_operations: OrderedSet[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m OrderedSet()\n\u001B[0;32m   1808\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavailable_buffer_names \u001B[38;5;241m=\u001B[39m OrderedSet(\n\u001B[0;32m   1809\u001B[0m     [\n\u001B[0;32m   1810\u001B[0m         \u001B[38;5;241m*\u001B[39mV\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mgraph_inputs\u001B[38;5;241m.\u001B[39mkeys(),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1813\u001B[0m     ]\n\u001B[0;32m   1814\u001B[0m )\n\u001B[1;32m-> 1816\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_scheduler_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m nodes]\n\u001B[0;32m   1817\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_zero_dim_cpu_tensor()\n\u001B[0;32m   1818\u001B[0m \u001B[38;5;66;03m# some new constants could have been created above\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1947\u001B[0m, in \u001B[0;36mScheduler.create_scheduler_node\u001B[1;34m(self, node)\u001B[0m\n\u001B[0;32m   1945\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NopKernelSchedulerNode(\u001B[38;5;28mself\u001B[39m, node)\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, (ir\u001B[38;5;241m.\u001B[39mComputedBuffer, ir\u001B[38;5;241m.\u001B[39mTemplateBuffer)):\n\u001B[1;32m-> 1947\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSchedulerNode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, ir\u001B[38;5;241m.\u001B[39mExternKernel):\n\u001B[0;32m   1949\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ExternKernelSchedulerNode(\u001B[38;5;28mself\u001B[39m, node)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:893\u001B[0m, in \u001B[0;36mSchedulerNode.__init__\u001B[1;34m(self, scheduler, node)\u001B[0m\n\u001B[0;32m    891\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(scheduler)\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_from_node(node)\n\u001B[1;32m--> 893\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_attrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:907\u001B[0m, in \u001B[0;36mSchedulerNode._compute_attrs\u001B[1;34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001B[0m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sizes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39msimplify_and_reorder(\n\u001B[0;32m    902\u001B[0m     extra_indexing_constraints\u001B[38;5;241m=\u001B[39mextra_indexing_constraints,\n\u001B[0;32m    903\u001B[0m     recompute_sizes_body_func\u001B[38;5;241m=\u001B[39mrecompute_sizes_body_func,\n\u001B[0;32m    904\u001B[0m )\n\u001B[0;32m    906\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mget_device_or_error()\n\u001B[1;32m--> 907\u001B[0m group_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgroup_fn\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m (device, group_fn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sizes))\n\u001B[0;32m    910\u001B[0m \u001B[38;5;66;03m# Don't normalize since normalization will merge loops which\u001B[39;00m\n\u001B[0;32m    911\u001B[0m \u001B[38;5;66;03m# makes it hard to decide new loop orders.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:3441\u001B[0m, in \u001B[0;36mScheduler.get_backend\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m   3439\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackends:\n\u001B[1;32m-> 3441\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackends[device] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3442\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackends[device]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchXPU\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:3432\u001B[0m, in \u001B[0;36mScheduler.create_backend\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m   3428\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   3429\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_props\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_props\u001B[38;5;241m.\u001B[39mmajor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_props\u001B[38;5;241m.\u001B[39mminor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# noqa: B950\u001B[39;00m\n\u001B[0;32m   3430\u001B[0m         )\n\u001B[0;32m   3431\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m is_gpu(device\u001B[38;5;241m.\u001B[39mtype):\n\u001B[1;32m-> 3432\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   3433\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# noqa: B950\u001B[39;00m\n\u001B[0;32m   3434\u001B[0m         )\n\u001B[0;32m   3436\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m device_scheduling(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[1;31mBackendCompilerFailed\u001B[0m: backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "# Create tensorboard logger in a new folder, so I have everything logged everytime, since I often forget and then it writes multiple runs into one folder which is a pain to separate. \n",
    "# Get the new folder path\n",
    "log_dir = get_next_run_folder('GPT2_Model')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Initialize SummaryWriter with the new log directory\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(f\"Logging to: {log_dir}\")\n",
    "\n",
    "# Training loop\n",
    "num_training_steps = num_epochs * len(dataloader)\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# Make adjustment to the model\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "# Compile model for additional training speed\n",
    "# Torch compile uses the triton backend, which I have not installed. As it turns out its easy to install via pip, but not for intel arc gpus. I will have to dual boot my pc into ubuntu 22.04 in order to install the intel xpu backend for triton. As I like the pycharm environment and I am used to Windows pcs, I will set up ubuntu server and use it as a remote development server and access it via my laptop. This is not the first time I have done this. When it works it works greate, but it takes a lot of time to get running. \n",
    "model = torch.compile(model)\n",
    "\n",
    "# Enable memory optimizations (we can get away with less memory)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Cosin Anneling with Warmup as learning rate schedluer\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocabulary[-1] + 1)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        input_ids = batch[0].to(device).long() \n",
    "        attention_mask = batch[1].to(device).long() \n",
    "        # Create the labels which are just the inputs shifted to the right with a padding token at the end\n",
    "        labels = torch.cat(\n",
    "            [input_ids[:, 1:], \n",
    "             torch.full((len(input_ids), 1), padding_token, device=device, dtype=torch.long)],\n",
    "            dim=1\n",
    "        )\n",
    "        # Zero gradients before the backward pass (best practice for pytorch)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass using half precision to get away with even less memory\n",
    "        with torch.autocast(device_type='xpu', dtype=torch.float16):\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            # GPT-2 directly computes the loss if labels are provided\n",
    "            loss = outputs.loss  \n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping to prevent exploding gradients\n",
    "        total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        # Update learning rate\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # Log some statistics\n",
    "        detached_loss = loss.detach().cpu().item()\n",
    "        total_loss += detached_loss\n",
    "        global_step = epoch * len(dataloader) + batch_idx\n",
    "        writer.add_scalar('Training Loss', detached_loss, global_step)\n",
    "        writer.add_scalar('Learning Rate', lr_scheduler.get_last_lr()[0], global_step)\n",
    "        writer.add_scalar('Gradient Norm', total_norm, global_step)\n",
    "        # Add if statement to prevent numerical overflow\n",
    "        perplexity = math.exp(detached_loss) if detached_loss < 20 else float('inf')\n",
    "        writer.add_scalar('Perplexity', perplexity, global_step)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    train_loss.append(total_loss / len(dataloader))\n",
    "    total_loss = 0\n",
    "\n",
    "print('Training completed!')\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-17T13:36:55.542209900Z",
     "start_time": "2025-02-17T13:36:54.338593700Z"
    }
   },
   "id": "5ff3da0bebd28913",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model, 'gpt_model.ph')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-17T13:36:55.538209400Z"
    }
   },
   "id": "5e26c322b6954a6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
